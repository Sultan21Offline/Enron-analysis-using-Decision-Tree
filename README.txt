Goals:
1.Collecting the Datasets.
2.Data cleaning.
3.Data analysis.
4.Training our predicting model.
5.Results.


TO DO list:

1)Two data is collected and was initialized:The first dataset contains mail and the contents of messages that were sent by company employees to each other. Almost all data is crammed into a single column, so we will separate it so that it is easier to analyze.
The second dataset contains the financial data of employees. Based on them, we can make an algorithm that predicts people who were involved in fraudulent activities. And then check if our predictions coincided with those given on kaggle.


2)It is assumed that the data will be cleared and ready for analysis. Using the decision tree algorithm, we will distribute the data into classes using the first dataset. For the second dataset, with the same algorithm, we will distribute the data to the guilty and not guilty. We write with and without a library and compare accuracy.


3)Error correction. Testing. Check if the algorithm scatters our messages into classes correctly. We will check the accuracy of our predictions by adding a comparison with other algorithms.
We will add a new employee by entering his financial affairs. Check if our employee will be a suspect or not?

package.pkl - dataset.
